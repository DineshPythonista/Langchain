{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPEN_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(openai_api_key = os.environ[\"OPEN_API_KEY\"],temperature=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " in 2020\n",
      "\n",
      "Yes, studying large language models is still worth it in 2020. Large language models have become increasingly popular in recent years, and they are used in many applications such as natural language processing, machine translation, automatic summarization, and question-answering. By learning about large language models, you can gain a better understanding of how they work and how they can be used to develop more advanced applications.\n"
     ]
    }
   ],
   "source": [
    "text = \"Is studying about large language model is worth\"\n",
    "\n",
    "print(llm.predict(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dinesh/college/proj/langchain/venv/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:127: FutureWarning: '__init__' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '1.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from langchain import HuggingFaceHub\n",
    "llm_huggingface = HuggingFaceHub(repo_id=\"google/flan-t5-base\", model_kwargs={\"temperature\" : 0, \"max_length\" : 64})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The spokesman for the CIA said that the CIA had no intention of releasing the information.\n"
     ]
    }
   ],
   "source": [
    "print(llm_huggingface.predict(\"Give me a paragraph \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me the capital of US'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate(input_variables=['country'],\n",
    "template = \"Tell me the capital of {country}\")\n",
    "\n",
    "prompt_template.format(country = \"US\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Washington, D.C.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "chain = LLMChain(llm = llm, prompt = prompt_template)\n",
    "print(chain.run(\"US\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining Multiple Chains Using simple Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "capital_template = PromptTemplate(input_variables=['country'],\n",
    "template = \"Tell me the capital of {country}\")\n",
    "\n",
    "capital_chain = LLMChain(llm = llm, prompt = capital_template)\n",
    "\n",
    "famous_template = PromptTemplate(input_variables=['capital'],\n",
    "template = \"what is famous in {capital}\")\n",
    "\n",
    "famous_chain = LLMChain(llm = llm, prompt = famous_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tokyo is famous for its bustling city life, delicious cuisine, and its many cultural attractions. Tokyo is home to some of the world's most iconic landmarks, such as the Tokyo Tower and the Imperial Palace. It is also a major shopping destination, with many of the world's largest and most fashionable department stores located in the city.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "chain = SimpleSequentialChain(chains=[capital_chain, famous_chain])\n",
    "print(chain.run(\"Japan\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "capital_template = PromptTemplate(input_variables=['country'],\n",
    "template = \"Tell me the capital of {country}\")\n",
    "\n",
    "capital_chain = LLMChain(llm = llm, prompt = capital_template, output_key=\"capital\")\n",
    "\n",
    "famous_template = PromptTemplate(input_variables=['capital'],\n",
    "template = \"what is famous in {capital}\")\n",
    "\n",
    "famous_chain = LLMChain(llm = llm, prompt = famous_template, output_key=\"famous\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "\n",
    "chain = SequentialChain(chains=[capital_chain, famous_chain],\n",
    "input_variables = ['country'],\n",
    "output_variables = ['capital', 'famous'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'country': 'Germany',\n",
       " 'capital': '\\n\\nThe capital of Germany is Berlin.',\n",
       " 'famous': ' It is a popular tourist destination known for its iconic landmarks such as the Brandenburg Gate, the Reichstag, and the Berlin Wall. Other famous attractions include the Museum Island, Checkpoint Charlie, and Alexanderplatz.'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain({'country' : 'Germany'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chatmodels With ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x140a9ec20>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x140fa9180>, temperature=0.6, openai_api_key='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', openai_proxy='')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatllm = ChatOpenAI(openai_api_key = os.environ[\"OPEN_API_KEY\"],temperature=0.6, model = \"gpt-3.5-turbo\")\n",
    "chatllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"To become a data scientist, you will need to develop a strong foundation in several key areas. Here are some subjects you should study:\\n\\n1. Mathematics and Statistics: Data science requires a solid understanding of mathematics and statistics. Focus on topics like linear algebra, calculus, probability, and statistical inference.\\n\\n2. Programming: Proficiency in programming languages is essential. Start with Python, as it is widely used in the data science community. Additionally, learn SQL for working with databases and R for statistical analysis.\\n\\n3. Machine Learning: Familiarize yourself with the principles and algorithms of machine learning. Study topics such as supervised and unsupervised learning, regression, classification, clustering, and dimensionality reduction.\\n\\n4. Data Manipulation and Analysis: Learn how to clean, transform, and manipulate data using tools like pandas in Python or dplyr in R. Gain expertise in exploratory data analysis (EDA) techniques and data visualization.\\n\\n5. Data Mining and Big Data: Understand the concepts of data mining and how to work with large datasets. Learn about distributed computing frameworks like Apache Hadoop and Apache Spark.\\n\\n6. Data Visualization: Develop skills in creating effective visualizations to communicate insights from data. Learn popular visualization libraries like Matplotlib, Seaborn, and ggplot2.\\n\\n7. Data Engineering: Familiarize yourself with concepts related to data engineering, including data pipelines, data warehousing, and data integration.\\n\\n8. Domain Knowledge: Gain expertise in the domain you wish to work in. Whether it's finance, healthcare, marketing, or any other field, understanding the specific domain will help you apply data science effectively.\\n\\n9. Communication and Presentation: Data scientists need to effectively communicate their findings and insights. Practice presenting complex ideas in a clear and concise manner.\\n\\n10. Continuous Learning: The field of data science is constantly evolving, so it's crucial to stay updated with new techniques, algorithms, and tools. Join online communities, participate in forums, and follow industry blogs to keep learning.\\n\\nRemember, becoming a data scientist is a continuous journey that requires a combination of theoretical knowledge and practical experience. Gain hands-on experience by working on real-world projects and building a strong portfolio to showcase your skills.\")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatllm([\n",
    "    SystemMessage(content=\"You are a data scientist\"),\n",
    "    HumanMessage(content = \"Please tell what i need to study to become a data scientist\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt Template + LLM + Output Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.schema import BaseOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CommaSeparatedOutput(BaseOutputParser):\n",
    "    def parse(self, text:str):\n",
    "        return text.strip().split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "template=\"Your are a helpful assistant. When the use given any input , you should generate 5 words synonyms in a comma seperated list\"\n",
    "human_template=\"{text}\"\n",
    "chatprompt=ChatPromptTemplate.from_messages([\n",
    "    (\"system\",template),\n",
    "    (\"human\",human_template)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=chatprompt|chatllm|CommaSeparatedOutput()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['strong', ' robust', ' mighty', ' potent', ' influential']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"text\":\"powerful\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
